# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3Hl1ipYL32bmM3AZlpTi-VZxLv1BX2a
"""

from numpy import mean
from numpy import std
from sklearn.model_selection import KFold
from keras.datasets import mnist
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
 
# load train and test dataset
def load_dataset():
  # load dataset
  (trainX, trainY), (testX, testY) = mnist.load_data()
  # reshape dataset to have a single channel
  trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) #make the input data from matrix to col
  testX = testX.reshape((testX.shape[0], 28, 28, 1))
  # one hot encode target values
  trainY = to_categorical(trainY)  #make the output in form of 0,1 if the value is 5 then output is 0000010000
  testY = to_categorical(testY)
  return trainX, trainY, testX, testY

def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm

def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(100, activation='relu'))
	model.add(Dense(10, activation='softmax')) 
	
	model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
	return model
def define_model2():
  model = Sequential()
  model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(28, 28, 1)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(MaxPooling2D((2, 2)))
  model.add(Flatten())
  model.add(Dense(100, activation='relu'))
  model.add(Dense(10, activation='softmax'))
  
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
  return model

def define_model3():
  model = Sequential()
  model.add(Conv2D(128, (3, 3), activation='relu', input_shape=(28, 28, 1)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(MaxPooling2D((2, 2)))
  model.add(Flatten())
  model.add(Dense(100, activation='relu'))
  model.add(Dense(10, activation='softmax'))
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
  return model
def define_model4():
  model = Sequential()
  model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(Conv2D(64, (3, 3), activation='relu'))
  model.add(MaxPooling2D((2, 2)))
  model.add(MaxPooling2D((2, 2)))
  model.add(Flatten())
  model.add(Dense(100, activation='relu'))
  model.add(Dense(10, activation='softmax'))
  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
  return model
  
def evaluate_model(dataX, dataY,model, n_folds=10):
	scores = list()
	# prepare cross validation
	kfold = KFold(n_folds, shuffle=True, random_state=1)
	
	for train_ix, test_ix in kfold.split(dataX):
		
		# select rows for train and test
		trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]
		# fit model
		model.fit(trainX, trainY, epochs=10, batch_size=3, verbose=0)
		# evaluate model
		_, acc = model.evaluate(testX, testY, verbose=0)
		print('> %.3f' % (acc * 100.0))
		# stores scores
		scores.append(acc)
	return scores

def summarize_performance(scores):
	
	print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))

def save_models():
  # load dataset
  trainX, trainY, testX, testY = load_dataset()
  
  trainX, testX = prep_pixels(trainX, testX)
  model = define_model()
  model2 = define_model2()
  model3 = define_model3()
  model4 = define_model4()
  # evaluate model
  scores = evaluate_model(trainX, trainY,model)
  scores2 = evaluate_model(trainX, trainY,model2)
  scores3 = evaluate_model(trainX, trainY,model3)
  scores4 = evaluate_model(trainX, trainY,model4)

  # summarize estimated performance
  summarize_performance(scores)
  summarize_performance(scores2)
  summarize_performance(scores3)
  summarize_performance(scores4)
   #fit model
  model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)
  model2.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)
  model3.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)
  model4.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)
  # save model
  model.save('model1')
  model2.save('model2')
  model3.save('model3')
  model4.save('model4')


save_models()

from keras.datasets import mnist
from keras.models import load_model
from keras.utils import to_categorical

trainX, trainY, testX, testY = load_dataset()

trainX, testX = prep_pixels(trainX, testX)
model=load_model('model1')
model2=load_model('model2')
model3=load_model('model3')
model4=load_model('model4')
_, acc = model.evaluate(testX, testY, verbose=0)
print('> %.3f' % (acc * 100.0))
_, acc2 = model2.evaluate(testX, testY, verbose=0)
print('> %.3f' % (acc2 * 100.0))
_, acc3 = model3.evaluate(testX, testY, verbose=0)
print('> %.3f' % (acc3 * 100.0))
_, acc4 = model4.evaluate(testX, testY, verbose=0)
print('> %.3f' % (acc4 * 100.0))



